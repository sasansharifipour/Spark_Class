{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_IO.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCmWDZtZZgf9MCMxDo3Feh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasansharifipour/Spark_Class/blob/main/Spark_IO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puKhIZV0DI_e"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\r\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\r\n",
        "\r\n",
        "import findspark\r\n",
        "findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgJC-8XKFoqZ"
      },
      "source": [
        "import pyspark \r\n",
        "from pyspark.sql import SparkSession\r\n",
        "sc = pyspark.SparkContext(appName=\"SQL_Operations\")\r\n",
        "\r\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6jhBgR6Fu1H"
      },
      "source": [
        "df4 = spark.read.load('/content/spark-3.0.1-bin-hadoop2.7/examples/src/main/resources/people.json', format=\"json\")\r\n",
        "\r\n",
        "df4.select(\"name\",\"age\").write.save(\"namesAndAges.parquet\", format=\"parquet\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtA1dPKGMuN"
      },
      "source": [
        "df5 = spark.read.load('/content/spark-3.0.1-bin-hadoop2.7/examples/src/main/resources/people.csv',format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84S6u2bvGfOG",
        "outputId": "a19461de-7885-4b17-ec00-8f786f25c2f2"
      },
      "source": [
        "df5.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|      name;age;job|\n",
            "+------------------+\n",
            "|Jorge;30;Developer|\n",
            "|  Bob;32;Developer|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwFM6TYNGgyu"
      },
      "source": [
        "df6 = spark.read.load('/content/spark-3.0.1-bin-hadoop2.7/examples/src/main/resources/people.csv',format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgF588AKGoim",
        "outputId": "12613c76-56d3-4242-f4aa-67980994cead"
      },
      "source": [
        "df6.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---+---------+\n",
            "| name|age|      job|\n",
            "+-----+---+---------+\n",
            "|Jorge| 30|Developer|\n",
            "|  Bob| 32|Developer|\n",
            "+-----+---+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9x2r-9CGqK2"
      },
      "source": [
        "# Run SQL onfiles directly\r\n",
        "df6 = spark.sql(\"SELECT * FROM parquet.`namesAndAges.parquet`\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gElbKAysG7te",
        "outputId": "9f926abf-365c-420d-afb2-8ad0ddb4bbfb"
      },
      "source": [
        "df6.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----+\n",
            "|   name| age|\n",
            "+-------+----+\n",
            "|Michael|null|\n",
            "|   Andy|  30|\n",
            "| Justin|  19|\n",
            "+-------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5T-x6rJHas9"
      },
      "source": [
        "peopleDF = spark.read.json('/content/spark-3.0.1-bin-hadoop2.7/examples/src/main/resources/people.json')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVsFPZLHxAm"
      },
      "source": [
        "peopleDF.write.parquet(\"people.parquet\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ5cD8j1H3KW"
      },
      "source": [
        "parquetFile = spark.read.parquet(\"people.parquet\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMRGkD65H-bn"
      },
      "source": [
        "parquetFile.createOrReplaceTempView(\"parquetFile\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJWlFL2qID8n"
      },
      "source": [
        "teenagers = spark.sql(\"SELECT name FROM parquetFile WHERE age >= 13 AND age <= 19\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skAP6S-mINwO",
        "outputId": "dbe1cbeb-31c2-4eb4-98c8-dd0dd960c6eb"
      },
      "source": [
        "teenagers.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|  name|\n",
            "+------+\n",
            "|Justin|\n",
            "+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SWVh52QIQE2"
      },
      "source": [
        "from pyspark.sql import Row\r\n",
        "\r\n",
        "squaresDF = spark.createDataFrame(sc.parallelize(range(1, 6))\r\n",
        "  .map(lambda i : Row(single=i, double = i ** 2)))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf82BjMBItTG",
        "outputId": "c3290c0b-8c40-4503-ac4f-f153e689efbb"
      },
      "source": [
        "squaresDF.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|single|double|\n",
            "+------+------+\n",
            "|     1|     1|\n",
            "|     2|     4|\n",
            "|     3|     9|\n",
            "|     4|    16|\n",
            "|     5|    25|\n",
            "+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JNxF4Y6Ivp1"
      },
      "source": [
        "squaresDF.write.parquet(\"data/test_table/key=1\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwdEhfBFI3k2"
      },
      "source": [
        "cubesDF = spark.createDataFrame(sc.parallelize(range(6, 11))\r\n",
        "  .map(lambda i : Row(single=i, double = i ** 3)))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJxe2utiJJYu",
        "outputId": "645161a6-c7e5-459c-dfbe-a1c85a1b3794"
      },
      "source": [
        "cubesDF.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|single|double|\n",
            "+------+------+\n",
            "|     6|   216|\n",
            "|     7|   343|\n",
            "|     8|   512|\n",
            "|     9|   729|\n",
            "|    10|  1000|\n",
            "+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r30A655FJLd1"
      },
      "source": [
        "cubesDF.write.parquet(\"data/test_table/key=2\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daQtRnC-JUD9"
      },
      "source": [
        "mergedDf = spark.read.option(\"mergeSchema\",\"true\").parquet(\"data/test_table\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJJC00hDJif2",
        "outputId": "a00a9f59-30ee-42e3-f797-cc329878f621"
      },
      "source": [
        "mergedDf.printSchema()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- single: long (nullable = true)\n",
            " |-- double: long (nullable = true)\n",
            " |-- key: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXkDLpveJk_m",
        "outputId": "9fbeabe0-10a2-4a09-a622-23e2a04ff947"
      },
      "source": [
        "mergedDf.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+---+\n",
            "|single|double|key|\n",
            "+------+------+---+\n",
            "|     8|   512|  2|\n",
            "|     9|   729|  2|\n",
            "|    10|  1000|  2|\n",
            "|     3|     9|  1|\n",
            "|     4|    16|  1|\n",
            "|     5|    25|  1|\n",
            "|     6|   216|  2|\n",
            "|     7|   343|  2|\n",
            "|     1|     1|  1|\n",
            "|     2|     4|  1|\n",
            "+------+------+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrvMwy9zJn9e"
      },
      "source": [
        "spark.stop()\r\n",
        "sc.stop()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muHdCk3UJvqG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}