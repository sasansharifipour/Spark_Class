{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPARK_CC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasansharifipour/Spark_Class/blob/main/SPARK_CC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mb5ZPJBVRlW"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2cYoDeOu0J7",
        "outputId": "c6e61288-be62-4d23-e922-c31085e398b3"
      },
      "source": [
        "file_download_link = \"https://drive.google.com/u/0/uc?id=1BgY3iHSZ0ImXc6atr61YQRcloxDwNrvi&export=download\" \n",
        "!wget -O paper_graph_adj_list.txt --no-check-certificate \"$file_download_link\"\n",
        "\n",
        "file_download_link = \"https://drive.google.com/u/0/uc?id=1qmwKYipNwJZyheNfVxW8GwzhbY6J2nPU&export=download\" \n",
        "!wget -O paper_graph_node_list.txt --no-check-certificate \"$file_download_link\""
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-25 11:07:51--  https://drive.google.com/u/0/uc?id=1BgY3iHSZ0ImXc6atr61YQRcloxDwNrvi&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.193.113, 173.194.193.102, 173.194.193.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.193.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qj71p43ejqtfpev0mlio6d3vc7301ehu/1619348850000/14577798666193718332/*/1BgY3iHSZ0ImXc6atr61YQRcloxDwNrvi?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-04-25 11:07:51--  https://doc-0s-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qj71p43ejqtfpev0mlio6d3vc7301ehu/1619348850000/14577798666193718332/*/1BgY3iHSZ0ImXc6atr61YQRcloxDwNrvi?e=download\n",
            "Resolving doc-0s-70-docs.googleusercontent.com (doc-0s-70-docs.googleusercontent.com)... 172.217.219.132, 2607:f8b0:4001:c13::84\n",
            "Connecting to doc-0s-70-docs.googleusercontent.com (doc-0s-70-docs.googleusercontent.com)|172.217.219.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101 [text/plain]\n",
            "Saving to: ‘paper_graph_adj_list.txt’\n",
            "\n",
            "paper_graph_adj_lis 100%[===================>]     101  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-25 11:07:51 (923 KB/s) - ‘paper_graph_adj_list.txt’ saved [101/101]\n",
            "\n",
            "--2021-04-25 11:07:51--  https://drive.google.com/u/0/uc?id=1qmwKYipNwJZyheNfVxW8GwzhbY6J2nPU&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.193.138, 173.194.193.102, 173.194.193.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.193.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-10-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pv8bo6ocspud8uctrcekc2r533f4dhet/1619348850000/14577798666193718332/*/1qmwKYipNwJZyheNfVxW8GwzhbY6J2nPU?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-04-25 11:07:52--  https://doc-10-70-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pv8bo6ocspud8uctrcekc2r533f4dhet/1619348850000/14577798666193718332/*/1qmwKYipNwJZyheNfVxW8GwzhbY6J2nPU?e=download\n",
            "Resolving doc-10-70-docs.googleusercontent.com (doc-10-70-docs.googleusercontent.com)... 172.217.219.132, 2607:f8b0:4001:c13::84\n",
            "Connecting to doc-10-70-docs.googleusercontent.com (doc-10-70-docs.googleusercontent.com)|172.217.219.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23 [text/plain]\n",
            "Saving to: ‘paper_graph_node_list.txt’\n",
            "\n",
            "paper_graph_node_li 100%[===================>]      23  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-25 11:07:52 (1.01 MB/s) - ‘paper_graph_node_list.txt’ saved [23/23]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXJ3ghNIZJY5"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IbTpAZzvmKD"
      },
      "source": [
        "def create_all_links(all_data):\n",
        "\n",
        "  result = []\n",
        "  cnt = len(all_data)\n",
        "\n",
        "  for i in range(cnt):\n",
        "    for j in range(i + 1, cnt):\n",
        "      if (all_data[i] < all_data[j]):\n",
        "        result.append( ((all_data[i], all_data[j]), 0))\n",
        "      else:\n",
        "        result.append( ((all_data[j], all_data[i]), 0))\n",
        "\n",
        "  return result\n",
        "\n",
        "def calc_cc(key, value):\n",
        "\n",
        "  result = []\n",
        "  cnt = len(value)\n",
        "\n",
        "  for i in range(cnt):\n",
        "    for j in range(i + 1, cnt):\n",
        "      if (value[i] < value[j]):\n",
        "        result.append( ((value[i], value[j]), key))\n",
        "      else:\n",
        "        result.append( ((value[j], value[i]), key))\n",
        "\n",
        "  return result\n",
        "\n",
        "def calc_car(key, value):\n",
        "\n",
        "  result = []\n",
        "\n",
        "  cnt = len(value)\n",
        "\n",
        "  for i in range(cnt):\n",
        "    for j in range(i + 1, cnt):\n",
        "      for k in range(j +1, cnt):\n",
        "        \n",
        "        if (key < value[k]):\n",
        "          first_data = (key, value[k])\n",
        "        else:\n",
        "          first_data = (value[k], key)\n",
        "\n",
        "        if (value[i] < value[j]):\n",
        "          second_data = (value[i], value[j])\n",
        "        else:\n",
        "          second_data = (value[j], value[i])\n",
        "    \n",
        "        result.append( (second_data , (first_data, 1)))\n",
        "\n",
        "        if (key < value[j]):\n",
        "          first_data = (key, value[j])\n",
        "        else:\n",
        "          first_data = (value[j], key)\n",
        "\n",
        "        if (value[i] < value[k]):\n",
        "          second_data = (value[i], value[k])\n",
        "        else:\n",
        "          second_data = (value[k], value[i])\n",
        "    \n",
        "        result.append( (second_data , (first_data, 1)))\n",
        "        \n",
        "        if (key < value[i]):\n",
        "          first_data = (key, value[i])\n",
        "        else:\n",
        "          first_data = (value[i], key)\n",
        "\n",
        "        if (value[k] < value[j]):\n",
        "          second_data = (value[k], value[j])\n",
        "        else:\n",
        "          second_data = (value[j], value[k])\n",
        "    \n",
        "        result.append( (second_data , (first_data, 1)))\n",
        "  return result\n",
        "\n",
        "def Convert(lst):\n",
        "  result = {}\n",
        "\n",
        "  for item in lst:\n",
        "    if (item[0] in result):\n",
        "      result[item[0]] = result[item[0]] + 1\n",
        "    else:\n",
        "      result[item[0]] = 1\n",
        "\n",
        "  return result\n",
        "\n",
        "def remove_only_one_time_appers(dic):\n",
        "  return sum(y / 2 for x,y in dic.items() if y> 1)\n",
        "\n",
        "def car_grouped_mix(key, value):\n",
        "  aggrigated = remove_only_one_time_appers(Convert(value))\n",
        "  return (key, aggrigated)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4UwD5cE-zpB"
      },
      "source": [
        "df = spark.sparkContext.textFile(\"paper_graph_adj_list.txt\")\n",
        "nodes = spark.sparkContext.textFile(\"paper_graph_node_list.txt\")\n",
        "\n",
        "temp_var = df.map(lambda k: k.split(\" \"))\n",
        "temp_nodes = nodes.map(lambda k: k.split(\" \"))\n",
        "\n",
        "all_links = temp_nodes.flatMap(lambda k : create_all_links(k))\n",
        "data = temp_var.map(lambda k : (k[0], k[1::]))\n",
        "\n",
        "cc_reduce = data.flatMap(lambda x: calc_cc(x[0], x[1]))\n",
        "data_cn = cc_reduce.groupByKey().map(lambda x : (x[0], len(list(x[1]))))\n",
        "\n",
        "car_reduce = data.flatMap(lambda x: calc_car(x[0], x[1]))\n",
        "grouped = car_reduce.groupByKey().map(lambda x : (x[0], list(x[1])))\n",
        "\n",
        "car_grouped_reduce = grouped.map(lambda x: (car_grouped_mix(x[0], x[1])))\n",
        "\n",
        "joined_data = car_grouped_reduce.union(all_links)\n",
        "join_by_all_links = joined_data.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "car_for_all_links = join_by_all_links.union(data_cn).reduceByKey(lambda x, y: x * y)\n",
        "car_for_all_links.collect()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}